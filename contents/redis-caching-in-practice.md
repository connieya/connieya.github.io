---
date: '2025-09-12'
title: 'DB 가 힘들어 해요 : 인덱스를 넘어 레디스 캐싱으로 조회 성능 올리기'
categories: ['cache']
---


개발자로서 우리는 항상 더 빠른 응답 속도와 더 나은 사용자 경험을 고민합니다. 특히 조회가 많은 이커머스 시스템에서 성능 개선은 숙명과도 같죠. 가장 먼저 떠오르는 해결책은 단연 '인덱스(Index)'입니다. 하지만 인덱스만으로 모든 것이 해결될까요?

## 인덱스의 한계

물론 인덱스는 훌륭한 친구입니다. 특정 조건의 데이터를 찾아내는 속도를 드라마틱하게 향상시켜 주니까요. 실제로 저 또한 인덱스만으로 조회 쿼리의 실행 계획을 개선하고 응답 속도를 N배 향상시킨 경험이 있습니다.

**[인덱스를 걸었는데, 왜 느리죠? (feat. 5초를 0.03초로 만든 쿼리 삽질기)](https://connieya.github.io/why-is-my-query-slow-after-indexing/)**

 하지만 사용자가 여러 필터(카테고리, 가격대, 브랜드, 색상...)를 조합하기 시작하면 이야기는 달라집니다. 모든 필터 조합에 맞춰 인덱스를 거는 건 사실상 불가능하고, 인덱스가 많아질수록 오히려 쓰기(Write) 성능에 악영향을 줍니다.
문득 이런 생각이 들었습니다.

자주 조회되는 데이터라는 것은 그만큼 요청이 많다는 의미입니다. 그런데 이 데이터가 자주 변경되지 않는다면, 매번 요청이 올 때마다 데이터베이스까지 가서 I/O 작업을 수행하는 것은 명백한 비효율이었습니다.

이 불필요한 I/O를 없애려면, 데이터를 꼭 데이터베이스에만 둘 필요는 없다는 결론에 다다랐습니다. I/O 작업 자체가 없는 메모리처럼 훨씬 빠른 곳에 데이터를 저장해두고 꺼내 쓴다면 어떨까요?

## Redis를 선택한 이유

캐싱을 위한 도구는 많지만, 저의 선택은 레디스였습니다. 이유는 명확했습니다.

- In-Memory 기반의 압도적인 속도: 모든 데이터를 디스크가 아닌 메모리에 저장하기에, DB와는 비교할 수 없는 응답 속도를 자랑합니다.
- 다채로운 자료구조: 단순한 Key-Value를 넘어 해시(Hashes), 정렬된 집합(Sorted Sets) 등 상황에 맞는 최적의 '그릇'을 제공합니다. 이는 데이터를 더 효율적으로 저장하고 관리할 수 있게 해줍니다.


자, 이제 레디스라는 강력한 무기를 들었으니, 어떤 적부터 공략할지 정해야겠죠?

## 상품 상세 페이지 캐싱

이커머스에서 사용자들이 가장 많이, 그리고 반복적으로 보는 페이지는 단연 '상품 상세 페이지'입니다. 여기에는 상품명, 가격, 브랜드, 설명, 그리고 '좋아요' 수 같은 데이터가 있죠.

- 상품명, 브랜드, 설명: 거의 바뀌지 않습니다.
- 가격: 가끔 프로모션으로 변경됩니다.
- 좋아요 수: 사용자의 행동에 따라 꽤 빈번하게 바뀝니다.


이렇게 데이터의 변경 빈도가 제각각이지만, 전반적으로는 '읽기' 작업이 '쓰기' 작업보다 압도적으로 많은, 캐싱을 적용하기에 완벽한 대상이었습니다.

## Hash vs String
상품 상세 정보는 여러 필드로 구성된 객체 형태이니, 레디스에 저장할 방법은 크게 두 가지였습니다.

- JSON String: 객체를 통째로 JSON 문자열로 직렬화해서 저장.
- Hash: 상품 ID를 Key로, 나머지 필드들을 Hash의 Field-Value 쌍으로 저장.

만약 가격이나 '좋아요' 수만 살짝 바뀌었는데, 거대한 JSON 문자열 전체를 다시 읽고, 수정하고, 덮어써야 한다면 너무 비효율적이지 않을까요?

반면 해시(Hash) 자료구조는 HINCRBY 같은 명령어로 '좋아요' 수만 원자적으로(atomic) 1 증가시키는 등 필드 단위의 부분 업데이트가 가능합니다. 이 유연함 때문에 저는 망설임 없이 해시를 선택했습니다.


## 캐시 무효화 전략
캐시를 도입하는 순간부터 우리는 "어떻게 데이터를 최신으로 유지할 것인가?"라는 질문에 답해야 합니다. 저는 데이터의 성격에 따라 전략을 다르게 가져가기로 했습니다.

### 1. 좋아요: 캐시가 먼저, DB는 나중에 (Cache-First)

'좋아요' 수는 실시간으로 화면에 반영되는 것이 사용자 경험에 좋습니다. 그리고 아주 잠깐 DB와 수치가 달라도 치명적인 문제는 아니죠.
그래서 과감한 아키텍처를 도입했습니다.
- 즉시 반응: 사용자가 '좋아요'를 누르면, 비즈니스 로직 처리 후 스프링 이벤트를 발행합니다.
- 캐시 선반영: 이벤트 리스너가 레디스 해시의 likeCount 필드를 HINCRBY로 즉시 증감시킵니다. 사용자는 새로고침하면 바로 변경된 숫자를 봅니다.
- 안정적인 DB 저장: 동시에, **카프카(Kafka)**로 '좋아요 변경' 이벤트를 발행합니다.
- 부하 최소화: 카프카 컨슈머는 이벤트를 모아 배치(Batch)로 처리하며, DB에 한 번에 집계 결과를 업데이트합니다.

이 방식 덕분에 '좋아요'가 폭주해도 DB는 전혀 부담을 느끼지 않고, 사용자는 빠른 피드백을 경험하게 됩니다.

### 2. 가격: DB가 먼저, 캐시는 따라와! (DB-First)
하지만 '가격'은 다릅니다. 돈과 관련된 데이터는 1원의 오차도 용납할 수 없습니다. 데이터 정합성이 무엇보다 중요하죠.

- 원본(Source of Truth)은 DB: 가격 변경 요청은 반드시 데이터베이스 트랜잭션 안에서 먼저 처리됩니다.
- DB 업데이트 성공 후: 트랜잭션이 성공적으로 커밋되면, 그 후에 캐시를 갱신합니다.
- 갱신? 아니, 삭제!: 이때 캐시를 새로운 값으로 '업데이트'하는 것보다, 그냥 해당 상품의 캐시 키를 DEL 명령어로 삭제하는 것이 더 안전하고 간단합니다. 다음에 해당 상품 조회 요청이 오면, 자연스럽게 캐시 미스(Cache Miss)가 발생하고 DB에서 가장 정확한 최신 정보를 읽어와 캐시를 다시 채우게 되니까요.

### 3. TTL: "혹시 모르니 들어두는 보험"
처음에는 '좋아요'나 '가격'이 변경될 때마다 명시적으로 캐시를 갱신해주니, TTL(Time-To-Live, 만료 시간)이 굳이 필요할까 생각했습니다. 하지만 시스템은 언제나 예상치 못한 곳에서 문제를 일으키죠.
개발자의 실수로 캐시 갱신 로직이 누락된다면?

비동기 메시지 유실로 DB와 싱크가 깨진다면?

이런 만일의 사태에, 오래된 데이터가 캐시에 영원히 남아있는 '고스트 데이터'가 될 수 있습니다. 그래서 저는 **안전장치(Safety Net)**로서 모든 캐시 키에 **긴 TTL(예: 24시간)**을 설정하기로 했습니다. 최악의 경우에도, 데이터는 최대 24시간만 틀어지고 결국엔 자동 갱신될 테니까요.
## 캐시 운영 이슈

캐시를 적용하고 나니 시스템은 평화로워 보였습니다. 하지만 트래픽이 몰리는 실제 환경은 우리가 상상하는 것보다 훨씬 가혹합니다.

### 1. 캐시 스탬피드: ‘오픈런’은 DB에서만은 제발...
매우 인기 있는 상품의 캐시가 만료되는 순간, 수백 개의 요청이 동시에 몰려들어 캐시 미스를 경험하고, 결국 이 모든 요청이 DB로 향하는 재앙. 바로 **캐시 스탬피드(Cache Stampede)**입니다.

- 1차 방어 (Jitter): 모든 캐시의 TTL을 '정확히 2시간'으로 설정하면, 비슷한 시간에 생성된 캐시들이 동시에 만료될 수 있습니다. 여기에 Jitter를 추가, 즉 TTL에 약간의 랜덤 시간(예: 2시간 ± 10분)을 부여하여 만료 시점을 분산시켜 DB 부하를 완화했습니다.
- 2차 방어 (분산 락): 하지만 Jitter도 단 하나의 '초인기 상품'이 만료될 때는 무력합니다. 이때는 **분산 락(Distributed Lock)**을 사용합니다. 캐시 미스를 경험한 스레드 중 오직 하나만 '락'을 획득하여 DB에 접근하고, 나머지는 잠시 대기 후 락을 획득한 스레드가 채워놓은 캐시를 사용하게 하는 것입니다. DB로 가는 문을 단 하나로 줄여버리는 강력한 전략이죠.

### 2. 캐시 관통: 없는 데이터를 향한 집착을 막아라!

악의적인 사용자가 존재하지 않는 상품 ID(-999 등)로 계속 요청을 보내면 어떻게 될까요? 캐시에는 당연히 데이터가 없으니 모든 요청이 캐시를 '관통'해 DB에 도달합니다.

이 공격을 막는 방법은 간단합니다. "없다는 사실"도 캐싱하는 것입니다.

DB 조회 결과 데이터가 null이면, "이 ID는 데이터가 없음"을 의미하는 특별한 값(예: __null__)을 짧은 TTL과 함께 캐시에 저장합니다. 그러면 이후의 모든 악성 요청은 DB까지 도달하지 못하고 캐시 선에서 차단됩니다.

## 성능 개선 효과
네, 물론입니다. 인덱스 튜닝만으로는 도달할 수 없었던 응답 속도와 시스템 안정성을 확보할 수 있었습니다.

캐싱은 단순히 'DB 조회 횟수를 줄이는' 기술이 아니었습니다. 데이터의 성격과 실시간성을 고민하고, 장애 시나리오를 예측하며, 시스템 전체의 흐름을 설계하는 과정이었습니다. 레디스라는 훌륭한 파트너와 함께한 이번 여정을 통해, 또 한 뼘 성장한 개발자가 된 것 같습니다.

혹시 지금 DB의 비명 소리를 듣고 계신가요? 그렇다면 이제, 캐싱의 세계로 떠나볼 시간입니다.
